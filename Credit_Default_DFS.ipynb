{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Repayment / Default Risk\n",
    "\n",
    "### Датасет\n",
    "\n",
    "Датасет состоит из 7 разных таблиц:\n",
    "\n",
    "* **application_train/application_test**: the main training and testing data with information about each loan application at Home Credit. Every loan has its own row and is identified by the SK_ID_CURR. The training application data comes with the TARGET with indicating 0: the loan was repaid and 1: the loan was not repaid.\n",
    "* **bureau**: data concerning client's previous credits from other financial institutions. Each previous credit has its own row in bureau and is identified by the SK_ID_BUREAU, Each loan in the application data can have multiple previous credits.\n",
    "* **bureau_balance**: monthly data about the previous credits in bureau. Each row is one month of a previous credit, and a single previous credit can have multiple rows, one for each month of the credit length.\n",
    "* **previous_application**: previous applications for loans at Home Credit of clients who have loans in the application data. Each current loan in the application data can have multiple previous loans. Each previous application has one row and is identified by the feature SK_ID_PREV.\n",
    "* **POS_CASH_BALANCE**: monthly data about previous point of sale or cash loans clients have had with Home Credit. Each row is one month of a previous point of sale or cash loan, and a single previous loan can have many rows.\n",
    "* **credit_card_balance**: monthly data about previous credit cards clients have had with Home Credit. Each row is one month of a credit card balance, and a single credit card can have many rows.\n",
    "* **installments_payment**: payment history for previous loans at Home Credit. There is one row for every made payment and one row for every missed payment.\n",
    "\n",
    "Диаграмма ниже (предоставленная Home Credit) показывает, как связаны таблицы. Это будет очень полезно, когда нам нужно определить зависимости в featuretools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](home_credit.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import featuretools as ft\n",
    "import featuretools.variable_types as vtypes\n",
    "\n",
    "import sys\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the datasets and limit to the first 1000 rows (sorted by SK_ID_CURR) \n",
    "# This allows us to actually see the results in a reasonable amount of time! \n",
    "app_train = pd.read_csv('application_train.csv').sort_values('SK_ID_CURR').reset_index(drop = True)\n",
    "app_test = pd.read_csv('application_test.csv').sort_values('SK_ID_CURR').reset_index(drop = True)\n",
    "bureau = pd.read_csv('bureau.csv').sort_values(['SK_ID_CURR', 'SK_ID_BUREAU']).reset_index(drop = True)\n",
    "bureau_balance = pd.read_csv('bureau_balance.csv').sort_values('SK_ID_BUREAU').reset_index(drop = True)\n",
    "cash = pd.read_csv('POS_CASH_balance.csv').sort_values(['SK_ID_CURR', 'SK_ID_PREV']).reset_index(drop = True)\n",
    "credit = pd.read_csv('credit_card_balance.csv').sort_values(['SK_ID_CURR', 'SK_ID_PREV']).reset_index(drop = True)\n",
    "previous = pd.read_csv('previous_application.csv').sort_values(['SK_ID_CURR', 'SK_ID_PREV']).reset_index(drop = True)\n",
    "installments = pd.read_csv('installments_payments.csv').sort_values(['SK_ID_CURR', 'SK_ID_PREV']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = app_train.replace({365243: np.nan})\n",
    "app_test = app_test.replace({365243: np.nan})\n",
    "bureau = bureau.replace({365243: np.nan})\n",
    "bureau_balance = bureau_balance.replace({365243: np.nan})\n",
    "cash = cash.replace({365243: np.nan})\n",
    "credit = credit.replace({365243: np.nan})\n",
    "previous = previous.replace({365243: np.nan})\n",
    "installments = installments.replace({365243: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add identifying column\n",
    "app_test[\"TARGET\"] = np.nan\n",
    "\n",
    "# Append the dataframes\n",
    "app = app_train.append(app_test, ignore_index = True, sort = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in ['SK_ID_CURR', 'SK_ID_PREV', 'SK_ID_BUREAU']:\n",
    "    for dataset in [app, bureau, bureau_balance, cash, credit, previous, installments]:\n",
    "        if index in list(dataset.columns):\n",
    "            dataset[index] = dataset[index].fillna(0).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основы Featuretools\n",
    "\n",
    "Featuretools - это библиотека Python с открытым исходным кодом, предназначенная для автоматического создания признаков из набора связанных таблиц с использованием метода **Deep Feature Synthesis**\n",
    "\n",
    "Основные концепции Featuretools:\n",
    "\n",
    "* **Entities и EntitySets**: наши таблицы и структура данных \n",
    "* **Relations between tables**: связи таблицы друг с другом\n",
    "* **Feature Primitives**: агрегаты и преобразования, составленные для построения признаков\n",
    "* **Deep Feature Synthesis**: метод, использующий примитивы объектов для создания тысяч новых признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Entity and EntitySets / Сущности и наборы сущностей\n",
    "\n",
    "Entity - это просто таблица или датафрейм в Pandas. Объекты должны быть в строках, а признаки - в столбцах.\n",
    "\n",
    "Entity (cущность) в featuretools должна иметь уникальный индекс, в котором ни один из элементов не дублируется. В настоящее время только app, bureau и previous имеют уникальные индексы (SK_ID_CURR, SK_ID_BUREAU и SK_ID_PREV, соответственно).\n",
    "\n",
    "Для других датареймов данных, когда мы создаем сущности из них, мы должны передать make_index = True и затем указать имя индекса.\n",
    "\n",
    "Сущности также могут иметь **временные индексы**, которые отражают, когда информация в строке стала известной (доступной во времени). (Ни в одной из данных нет даты-времени, но есть относительные времена в месяцах или днях, которые можно рассматривать как переменные времени, хотя мы не будем использовать их как время в нашем случае, представляя их независимыми).\n",
    "\n",
    "EntitySet - это набор таблиц и взаимосвязей между ними. Это можно представить как структуру данных со своими собственными методами и атрибутами. Использование EntitySet позволяет нам группировать несколько таблиц и значительно упростит создание признаков, чем отслеживание отдельных таблиц и связей. EntitySet и Entities (Cущности) - это абстракции, которые можно применять к любому набору данных, поскольку они не зависят от базовых данных.\n",
    "\n",
    "Сначала мы создадим пустой набор сущностей с именами клиентов для отслеживания всех данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity set with id applications\n",
    "es = ft.EntitySet(id = 'clients')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Типы переменных\n",
    "\n",
    "Featuretools автоматически распознает типы переменных.\n",
    "\n",
    "Однако могут быть случаи, когда нам нужно явно указать featuretools тип переменной, например, когда boolean переменная представляется в виде целого числа.\n",
    "\n",
    "Типы переменных в featuretools можно указывать в виде словаря.\n",
    "\n",
    "Сначала мы будем работать с данными app, чтобы указать правильные типы переменных. Чтобы идентифицировать булевы переменные, которые записаны как числа (1.0 или 0.0), мы можем перебрать данные и найти любые столбцы, в которых есть только 2 уникальных значения и тип данных числовой. Мы также можем использовать определения столбцов, чтобы найти любые другие типы данных, которые должны быть идентифицированы, такие как Порядковые переменные. Определение правильных типов переменных важно, потому что Featuretools применяет различные операции к разным типам данных (так же, как мы это делаем при ручном проектировании признаков)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32 Boolean variables in the application data.\n"
     ]
    }
   ],
   "source": [
    "app_types = {}\n",
    "\n",
    "# Handle the Boolean variables:\n",
    "for col in app:\n",
    "    if (app[col].nunique() == 2) and (app[col].dtype == float):\n",
    "        app_types[col] = vtypes.Boolean\n",
    "\n",
    "# Remove the `TARGET`\n",
    "del app_types['TARGET']\n",
    "\n",
    "print('There are {} Boolean variables in the application data.'.format(len(app_types)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal variables\n",
    "app_types['REGION_RATING_CLIENT'] = vtypes.Ordinal\n",
    "app_types['REGION_RATING_CLIENT_W_CITY'] = vtypes.Ordinal\n",
    "app_types['HOUR_APPR_PROCESS_START'] = vtypes.Ordinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблица previous - единственная сущность, которая имеет признаки, которые должны быть записаны как логические. Правильное определение типа столбца предотвратит создание инструментальными средствами ненужных объектов, таких как среднее или максимальное значение от булевых переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 Boolean variables in the previous data.\n"
     ]
    }
   ],
   "source": [
    "previous_types = {}\n",
    "\n",
    "# Handle the Boolean variables:\n",
    "for col in previous:\n",
    "    if (previous[col].nunique() == 2) and (previous[col].dtype == float):\n",
    "        previous_types[col] = vtypes.Boolean\n",
    "\n",
    "print('There are {} Boolean variables in the previous data.'.format(len(previous_types)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В дополнение к идентификации булевых переменных, мы хотим убедиться, что featuretools не создает бессмысленных функций, таких как статистические агрегации (среднее, максимальное и т. Д.) айдишников. Все данные credit, cash, installments имеют переменную SK_ID_CURR. Однако нам на самом деле не нужна эта переменная в этих кадрах данных, поскольку мы связываем их с app через таблицу previous с помощью переменной SK_ID_PREV.\n",
    "\n",
    "Мы не хотим создавать признаки и из SK_ID_CURR, так как это произвольный идентификатор и не должен обладать предсказательной силой. Наши опции для обработки этих переменных - либо указывать featuretools игнорировать их, либо отбрасывать признаки перед их включением в набор сущностей. Мы примем последний подход."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all files in partition 1 to partitions/p1.\n",
      "Saved all files in partition 11 to partitions/p11.\n",
      "Saved all files in partition 21 to partitions/p21.\n",
      "Saved all files in partition 31 to partitions/p31.\n",
      "Saved all files in partition 41 to partitions/p41.\n",
      "Saved all files in partition 51 to partitions/p51.\n",
      "Saved all files in partition 61 to partitions/p61.\n",
      "Saved all files in partition 71 to partitions/p71.\n",
      "Saved all files in partition 81 to partitions/p81.\n",
      "Saved all files in partition 91 to partitions/p91.\n",
      "Saved all files in partition 101 to partitions/p101.\n",
      "Partitioning took 3 seconds.\n"
     ]
    }
   ],
   "source": [
    "installments = installments.drop(columns = ['SK_ID_CURR'])\n",
    "credit = credit.drop(columns = ['SK_ID_CURR'])\n",
    "cash = cash.drop(columns = ['SK_ID_CURR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Добавление сущностей\n",
    "\n",
    "Теперь мы определяем каждую сущность или таблицу данных и добавляем ее в EntitySet. Нам нужно передать индекс, если в таблице он есть, или make_index = True, если нет. В случаях, когда нам нужно создать индекс, мы должны предоставить имя для индекса. Нам также нужно передать словарь переменных типов, если есть какие-то конкретные переменные, которые мы должны идентифицировать. Следующий код добавляет все семь таблиц в EntitySet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entities with a unique index\n",
    "es = es.entity_from_dataframe(entity_id = 'app', dataframe = app, index = 'SK_ID_CURR',\n",
    "                              variable_types = app_types)\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id = 'bureau', dataframe = bureau, index = 'SK_ID_BUREAU')\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id = 'previous', dataframe = previous, index = 'SK_ID_PREV',\n",
    "                              variable_types = previous_types)\n",
    "\n",
    "# Entities that do not have a unique index\n",
    "es = es.entity_from_dataframe(entity_id = 'bureau_balance', dataframe = bureau_balance, \n",
    "                              make_index = True, index = 'bureaubalance_index')\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id = 'cash', dataframe = cash, \n",
    "                              make_index = True, index = 'cash_index')\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id = 'installments', dataframe = installments,\n",
    "                              make_index = True, index = 'installments_index')\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id = 'credit', dataframe = credit,\n",
    "                              make_index = True, index = 'credit_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: clients\n",
       "  Entities:\n",
       "    app [Rows: 356255, Columns: 122]\n",
       "    bureau [Rows: 1716428, Columns: 17]\n",
       "    previous [Rows: 1670214, Columns: 37]\n",
       "    bureau_balance [Rows: 27299925, Columns: 4]\n",
       "    cash [Rows: 10001358, Columns: 9]\n",
       "    installments [Rows: 13605401, Columns: 9]\n",
       "    credit [Rows: 3840312, Columns: 24]\n",
       "  Relationships:\n",
       "    No relationships"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display entityset so far\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EntitySet позволяет нам сгруппировать все наши таблицы в одну структуру данных. Это намного проще, чем манипулировать таблицами по одной (как мы должны делать при ручном проектировании признаков)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Связи / Relationships\n",
    "\n",
    "Отношения являются фундаментальной концепцией не только в FeatureTools, но и в любой реляционной базе данных. Наиболее распространенный тип отношений - один-ко-многим. Лучший способ думать об отношениях «один ко многим» - это аналогия родителей с ребенком. Родитель - единственный человек, но может иметь несколько детей. В контексте таблиц родительская таблица будет иметь одну строку (наблюдение) для каждого человека, в то время как дочерняя таблица может иметь много наблюдений для каждого родителя. В родительской таблице каждый индивид имеет одну строку и уникально идентифицируется индексом (также называемым ключом). У каждого человека в родительской таблице может быть несколько строк в дочерней таблице. Все становится немного сложнее, потому что у дочерних таблиц могут быть собственные дети, что делает этих внуков родителями.\n",
    "\n",
    "В качестве примера отношения «родитель-ребенок», в фрейме данных приложения имеется одна строка для каждого клиента (идентифицируемая SK_ID_CURR), в то время как в фрейме данных bureau есть несколько предыдущих кредитов для каждого клиента. Поэтому bureau является дочерним по отношению к датафрейму app. Bureau в свою очередь, является родительским для bureau_balance, потому что у каждого займа есть одна строка в бюро (идентифицированная как SK_ID_BUREAU), но несколько записей за месяц в bureau_balance. Когда мы выполняем ручное проектирование признаков, отслеживание всех этих отношений - это огромные затраты времени (и потенциальный источник ошибок), но мы можем добавить эти отношения в наш EntitySet и позволить Featuretools беспокоиться о сохранности таблиц.\n",
    "\n",
    "#### 4.1. Добавление зависимостей\n",
    "\n",
    "Определить relationships просто, используя диаграмму для таблиц данных (см. рисунок). Для каждой связи нам нужно сначала указать родительскую переменную, а затем дочернюю переменную. Всего между таблицами существует 6 взаимосвязей (считая отношения обучения и тестирования как одну). Ниже мы указываем эти отношения, а затем добавляем их в EntitySet.\n",
    "\n",
    "Традиционно мы используем отношения между родителями и детьми для агрегирования данных, группируя всех детей для одного родителя и вычисляя статистику. Например, мы можем сгруппировать все кредиты для одного клиента и рассчитать среднюю сумму кредита. Это просто, но может стать чрезвычайно утомительным, если мы хотим сделать сотни таких функций. Делать это по одному крайне неэффективно, особенно потому, что мы заканчиваем переписывать большую часть кода снова и снова, и этот код не может быть использован для какой-либо другой проблемы!\n",
    "\n",
    "Ситуация становится еще хуже, когда мы должны объединить внуков, потому что мы должны использовать два шага: сначала объединить на уровне родителей, а затем на уровне родителей. Скоро мы увидим, что featuretools может выполнять эту работу автоматически за нас, генерируя тысячи функций из всех таблиц данных. Когда мы делали это вручную, для каждой функции требовалось около 15 минут (как мы видели в записной книжке по ручному проектированию функций), поэтому featuretools потенциально экономит нам сотни часов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between app_train and bureau\n",
    "r_app_bureau = ft.Relationship(es['app']['SK_ID_CURR'], es['bureau']['SK_ID_CURR'])\n",
    "\n",
    "# Relationship between bureau and bureau balance\n",
    "r_bureau_balance = ft.Relationship(es['bureau']['SK_ID_BUREAU'], es['bureau_balance']['SK_ID_BUREAU'])\n",
    "\n",
    "# Relationship between current app and previous apps\n",
    "r_app_previous = ft.Relationship(es['app']['SK_ID_CURR'], es['previous']['SK_ID_CURR'])\n",
    "\n",
    "# Relationships between previous apps and cash, installments, and credit\n",
    "r_previous_cash = ft.Relationship(es['previous']['SK_ID_PREV'], es['cash']['SK_ID_PREV'])\n",
    "r_previous_installments = ft.Relationship(es['previous']['SK_ID_PREV'], es['installments']['SK_ID_PREV'])\n",
    "r_previous_credit = ft.Relationship(es['previous']['SK_ID_PREV'], es['credit']['SK_ID_PREV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: clients\n",
       "  Entities:\n",
       "    app [Rows: 356255, Columns: 122]\n",
       "    bureau [Rows: 1716428, Columns: 17]\n",
       "    previous [Rows: 1670214, Columns: 37]\n",
       "    bureau_balance [Rows: 27299925, Columns: 4]\n",
       "    cash [Rows: 10001358, Columns: 9]\n",
       "    installments [Rows: 13605401, Columns: 9]\n",
       "    credit [Rows: 3840312, Columns: 24]\n",
       "  Relationships:\n",
       "    bureau.SK_ID_CURR -> app.SK_ID_CURR\n",
       "    bureau_balance.SK_ID_BUREAU -> bureau.SK_ID_BUREAU\n",
       "    previous.SK_ID_CURR -> app.SK_ID_CURR\n",
       "    cash.SK_ID_PREV -> previous.SK_ID_PREV\n",
       "    installments.SK_ID_PREV -> previous.SK_ID_PREV\n",
       "    credit.SK_ID_PREV -> previous.SK_ID_PREV"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add in the defined relationships\n",
    "es = es.add_relationships([r_app_bureau, r_bureau_balance, r_app_previous,\n",
    "                           r_previous_cash, r_previous_installments, r_previous_credit])\n",
    "# Print out the EntitySet\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опять же, мы видим преимущества использования EntitySet, который может отслеживать все отношения между таблицами. Это позволяет нам работать на более высоком уровне абстракции, думая обо всем наборе данных, а не о каждой отдельной таблице, значительно повышая нашу эффективность.\n",
    "\n",
    "**Немного сложное замечание**: мы должны быть осторожны, чтобы не создавать diamond graph, где есть несколько путей от родителя к потомку Если мы напрямую свяжем app и cash через SK_ID_CURR; previous и cash через SK_ID_PREV; и app и previous через SK_ID_CURR, мы создали два пути от app к cash. Это приводит к неоднозначности, поэтому вместо этого мы должны связать app с cash через previous. Мы устанавливаем связь между previpus (родительским) и cash (дочерним) с использованием SK_ID_PREV. Затем мы устанавливаем связь между app (родительским) и previous (теперь дочерним), используя SK_ID_CURR. Затем featuretools смогут создавать признаки в app, полученные как из previous, так и из cash, путем объединения нескольких примитивов.\n",
    "\n",
    "Если в этом нет особого смысла, просто не забудьте включить только один путь от родителя к потомкам. Например, связать дедушку с внуком через родителя, а не напрямую через общую переменную.\n",
    "\n",
    "Все сущности в сущности могут быть связаны через эти отношения (relations). Теоретически это позволяет нам рассчитывать признаки для любой из сущностей, но на практике мы будем вычислять признаки только для датафрейма app, поскольку он будет использоваться для обучения / тестирования. Конечным результатом будет датафрейм, содержащий по одной строке для каждого клиента в приложении с тысячами признаков для каждого отдельного клиента.\n",
    "\n",
    "Мы почти приступили к созданию тысяч признаков, но у нас еще есть несколько основополагающих тем для понимания. Следующий строительный блок - это примитивы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Признаковые примитивы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примитив объекта - это операция, применяемая к таблице или набору таблиц для создания признака. Они представляют собой простые расчеты, многие из которых мы уже используем в ручном проектировании признаков, которые можно накладывать друг на друга для создания сложных глубоких элементов. Особые примитивы делятся на две категории:\n",
    "\n",
    "* **Агрегация**: функция, которая группирует детей для каждого родителя и вычисляет статистику, такую как среднее, минимальное, максимальное или стандартное отклонение для детей. Примером является максимальная сумма предыдущего кредита для каждого клиента. Агрегация охватывает несколько таблиц с использованием связей между таблицами.\n",
    "* **Преобразование**: операция, примененная к одному или нескольким столбцам в одной таблице. В качестве примера можно взять абсолютное значение столбца или найти разницу между двумя столбцами в одной таблице.\n",
    "\n",
    "Список доступных примитивов функций в featuretools можно посмотреть ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cum_count</td>\n",
       "      <td>transform</td>\n",
       "      <td>Calculates the cumulative count.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>greater_than_equal_to</td>\n",
       "      <td>transform</td>\n",
       "      <td>Determines if values in one list are greater than or equal to another list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>latitude</td>\n",
       "      <td>transform</td>\n",
       "      <td>Returns the first tuple value in a list of LatLong tuples.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>scalar_subtract_numeric_feature</td>\n",
       "      <td>transform</td>\n",
       "      <td>Subtract each value in the list from a given scalar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>week</td>\n",
       "      <td>transform</td>\n",
       "      <td>Determines the week of the year from a datetime.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>greater_than</td>\n",
       "      <td>transform</td>\n",
       "      <td>Determines if values in one list are greater than another list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>subtract_numeric</td>\n",
       "      <td>transform</td>\n",
       "      <td>Element-wise subtraction of two lists.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>second</td>\n",
       "      <td>transform</td>\n",
       "      <td>Determines the seconds value of a datetime.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>add_numeric</td>\n",
       "      <td>transform</td>\n",
       "      <td>Element-wise addition of two lists.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>negate</td>\n",
       "      <td>transform</td>\n",
       "      <td>Negates a numeric value.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               name       type  \\\n",
       "20                        cum_count  transform   \n",
       "21            greater_than_equal_to  transform   \n",
       "22                         latitude  transform   \n",
       "23  scalar_subtract_numeric_feature  transform   \n",
       "24                             week  transform   \n",
       "25                     greater_than  transform   \n",
       "26                 subtract_numeric  transform   \n",
       "27                           second  transform   \n",
       "28                      add_numeric  transform   \n",
       "29                           negate  transform   \n",
       "\n",
       "                                                                    description  \n",
       "20                                             Calculates the cumulative count.  \n",
       "21  Determines if values in one list are greater than or equal to another list.  \n",
       "22                   Returns the first tuple value in a list of LatLong tuples.  \n",
       "23                         Subtract each value in the list from a given scalar.  \n",
       "24                             Determines the week of the year from a datetime.  \n",
       "25              Determines if values in one list are greater than another list.  \n",
       "26                                       Element-wise subtraction of two lists.  \n",
       "27                                  Determines the seconds value of a datetime.  \n",
       "28                                          Element-wise addition of two lists.  \n",
       "29                                                     Negates a numeric value.  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the primitives in a dataframe\n",
    "primitives = ft.list_primitives()\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "primitives[primitives['type'] == 'transform'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Deep feature synthesis\n",
    "\n",
    "**Deep Feature Synthesis (DFS)** - это метод, который Featuretools использует для создания новых признаков. Стек DFS содержат примитивы для формирования объектов с «глубиной», равной количеству примитивов. Например, если мы берем максимальное значение предыдущих кредитов клиента (скажем, MAX (previous.loan_amount)), это «глубокий элемент» с глубиной 1. Чтобы создать элемент с глубиной два, мы могли бы сложить примитивы, принимая максимальное значение среднемесячных платежей клиента за предыдущий кредит (например, MAX (предыдущий (MEAN (installments.payment))))). В ручном проектировании функций это потребовало бы двух отдельных группировок и объединений и заняло более 15 минут, чтобы написать код для функции.\n",
    "\n",
    "**Deep Feature Synthesis** - чрезвычайно мощный метод, который позволяет нам преодолеть наши человеческие ограничения по времени и креативности, создавая признаки, о которых мы никогда не сможем думать самостоятельно (или не будем иметь терпения для их реализации). Кроме того, DFS применима к любому набору данных с очень незначительными изменениями синтаксиса. При проектировании функций мы обычно применяем одни и те же функции к нескольким наборам данных, но когда мы делаем это вручную, нам приходится переписывать код, потому что он специфичен для конкретной проблемы. Код Featuretools можно применять к любому набору данных, поскольку он написан на более высоком уровне абстракции.\n",
    "\n",
    "Оригинальную статью об автоматизированном проектировании объектов с использованием **Deep Feature Synthesis** стоит прочитать, если вы хотите понять концепции на более глубоком уровне.\n",
    "\n",
    "Для выполнения DFS в featuretools мы используем функцию dfs, передающую ей набор сущностей, target_entity (где мы хотим создавать функции), agg_primitives для использования, trans_primitives для использования, max_depth функций и ряд других аргументов в зависимости от нашего варианта использования. Есть также опции для мультиобработки с njobs и информацией, распечатанной с подробным описанием.\n",
    "\n",
    "Еще один важный аргумент - features_only. Если мы установим это в True, dfs будет делать только имена объектов, а не вычислять фактические значения объектов (называемые матрицей объектов). Это полезно, когда мы хотим проверить функцию, которая будет создана, и мы также можем сохранить функции для использования с другим набором данных (например, когда у нас есть данные обучения и тестирования)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Обычные примитивы\n",
    "\n",
    "Не используя знания предметной области, мы можем создавать тысячи признаков, используя примитивы по умолчанию в featuretools. Этот первый вызов будет использовать стандартные примитивы агрегации и преобразования, максимальную глубину 2, и вычислять примитивы для таблицы app. Мы будем генерировать только сами функции (имена, а не значения), которые мы можем сохранить и проверить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 1686 features\n"
     ]
    }
   ],
   "source": [
    "# Default primitives from featuretools\n",
    "default_agg_primitives =  [\"sum\", \"std\", \"max\", \"skew\", \"min\", \"mean\", \"count\", \"percent_true\", \"num_unique\", \"mode\"]\n",
    "default_trans_primitives =  [\"day\", \"year\", \"month\", \"weekday\", \"haversine\"]\n",
    "\n",
    "# DFS with specified primitives\n",
    "feature_names = ft.dfs(entityset = es, target_entity = 'app',\n",
    "                       trans_primitives = default_trans_primitives,\n",
    "                       agg_primitives=default_agg_primitives, \n",
    "                       where_primitives = [], seed_features = [],\n",
    "                       max_depth = 2, n_jobs = -1, verbose = 1,\n",
    "                       features_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Даже простой вызов deep feature synthesis дает нам более 1500 функций для работы. Конечно, не все из них будут важны, но это все равно представляет сотни часов, которые мы сэкономили. Более того, dfs может найти важные признаки, о которых мы никогда бы не подумали.\n",
    "\n",
    "Мы можем посмотреть на некоторые из названий признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Feature: MEAN(previous.MEAN(credit.AMT_RECIVABLE))>,\n",
       " <Feature: MEAN(previous.MEAN(credit.AMT_TOTAL_RECEIVABLE))>,\n",
       " <Feature: MEAN(previous.MEAN(credit.CNT_DRAWINGS_ATM_CURRENT))>,\n",
       " <Feature: MEAN(previous.MEAN(credit.CNT_DRAWINGS_CURRENT))>,\n",
       " <Feature: MEAN(previous.MEAN(credit.CNT_DRAWINGS_OTHER_CURRENT))>,\n",
       " <Feature: MEAN(previous.MEAN(credit.CNT_DRAWINGS_POS_CURRENT))>,\n",
       " <Feature: MEAN(previous.MEAN(credit.CNT_INSTALMENT_MATURE_CUM))>,\n",
       " <Feature: MEAN(previous.MEAN(credit.SK_DPD))>,\n",
       " <Feature: MEAN(previous.MEAN(credit.SK_DPD_DEF))>,\n",
       " <Feature: MEAN(previous.COUNT(credit))>,\n",
       " <Feature: MEAN(previous.NUM_UNIQUE(credit.NAME_CONTRACT_STATUS))>,\n",
       " <Feature: NUM_UNIQUE(previous.MODE(cash.NAME_CONTRACT_STATUS))>,\n",
       " <Feature: NUM_UNIQUE(previous.MODE(credit.NAME_CONTRACT_STATUS))>,\n",
       " <Feature: MODE(previous.MODE(cash.NAME_CONTRACT_STATUS))>,\n",
       " <Feature: MODE(previous.MODE(credit.NAME_CONTRACT_STATUS))>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[-15:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Бизнес признаки\n",
    "\n",
    "Featuretools автоматически создаст для нас тысячи признаков, но это не значит, что мы не можем использовать наши собственные знания для повышения эффективности прогнозирования. Featuretools может расширить наши знания предметной области, поставив дополнительные функции поверх наших возможностей, основанных на знании предметной области. Мы определили и создали множество полезных функций в блокноте по разработке функций для руководства, основываясь на наших собственных знаниях и знаниях тысяч ученых, работающих над этой проблемой в Kaggle. Вместо того, чтобы получать только одну функцию знания предметной области, мы можем эффективно получить десятки или даже сотни. Здесь мы объясним варианты использования знаний предметной области, но мы будем придерживаться простой реализации Featuretools для сравнения.\n",
    "\n",
    "Для получения дополнительной информации по любой из этих тем см. Документацию или другие записные книжки в этом хранилище.\n",
    "\n",
    "#### 6.1. Доменные функции / Seed features\n",
    "Seed functions - это доменные функции, которые мы вносим в данные, которые затем можно построить на Featuretools. Например, мы увидели, что ставка по кредиту является важной особенностью, поскольку кредит с более высокой ставкой, вероятно, более рискованный. В Featuretools мы можем закодировать ставку ссуды (как для текущей ссуды, так и для предыдущих ссуд) как начальную функцию, и Featuretools по мере возможности создаст дополнительные пояснительные переменные в этой области знаний.\n",
    "\n",
    "####  6.2. Важные значения / Interesting values\n",
    "Интересные значения имеют аналогичную идею для начальных функций, за исключением того, что они позволяют нам создавать условные элементы. Например, мы можем захотеть найти для каждого клиента среднюю сумму предыдущих кредитов, которые были закрыты, и среднюю сумму предыдущих кредитов, которые все еще активны. Указывая интересные значения в бюро через переменную CREDIT_ACTIVE, мы можем сделать так, чтобы Featuretools делал именно это! Выполнение этого вручную было бы чрезвычайно утомительным и предоставило бы многочисленные возможности для ошибок.\n",
    "\n",
    "####  6.3. Кастомные примитивы / Custom primitives\n",
    "Если мы не удовлетворены примитивами, доступными для использования в Featuretools, мы можем написать свои собственные функции для преобразования или агрегирования данных. Это одна из самых мощных возможностей в FeatureTools, поскольку она позволяет нам выполнять очень специфические операции, которые затем можно применять к нескольким наборам данных.\n",
    "\n",
    "В этой записной книжке мы сконцентрируемся на базовой реализации Featuretools, но помните, что эти возможности доступны для оптимизации библиотеки и использования знаний предметной области !:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Выбор примитивов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для нашего фактического набора функций мы будем использовать выбранную группу примитивов, а не только значения по умолчанию. Это создаст более 1800 признаков для использования в моделировании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify primitives\n",
    "agg_primitives =  [\"sum\", \"max\", \"min\", \"mean\", \"count\", \"percent_true\", \"num_unique\", \"mode\"]\n",
    "trans_primitives = ['percentile', 'and']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 1883 features\n"
     ]
    }
   ],
   "source": [
    "# Deep feature synthesis \n",
    "feature_names = ft.dfs(entityset=es, target_entity='app',\n",
    "                       agg_primitives = agg_primitives,\n",
    "                       trans_primitives = trans_primitives,\n",
    "                       n_jobs = -1, verbose = 1,\n",
    "                       features_only = True,\n",
    "                       max_depth = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft.save_features(feature_names, 'features.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Выводы\n",
    "В этом примере мы увидели, как реализовать автоматизированное создание признаков. Автоматизированное создание признаков позволяет нам создавать тысячи новых признаков из набора связанных таблиц данных, что значительно повышает нашу эффективность в качестве исследователей данных. Более того, мы все еще можем использовать знания предметной области в наших функциях и даже расширять наши знания предметной области, опираясь на наши собственные изготовленные вручную признаки.\n",
    "\n",
    "Основные выводы:\n",
    "\n",
    "* Автоматизированная разработка признаков заняла 1 час, а ручная разработка признаков - 10 часов.\n",
    "* Автоматизированное проектирование признаков построило тысячи признаков в несколько строк кода по сравнению с десятками строк кода на функцию для ручного проектирования.\n",
    "*В целом, производительность автоматизированных функций сопоставима или выше, чем у ручных функций (см. Блокнот «Результаты»).\n",
    "* Преимущества автоматизированного проектирования функций значительны и значительно помогут нам в роли исследователей данных. Это не уменьшит потребность в специалистах по данным, а скорее сделает нас более эффективными и построит лучшие пайплайны за меньшее время."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Следующие шаги\n",
    "\n",
    "После создания полного набора признаков мы можем применить отбор признаков и затем приступить к моделированию. Чтобы оптимизировать модель для функций, мы используем случайный поиск для 100 итераций по сетке гиперпараметров. Чтобы узнать, как использовать Dask для параллельного запуска Featuretools, обратитесь к Реализации Featuretools с записной книжкой Dask. Для выбора функции обратитесь к блокноту Выбор функции. Окончательные результаты представлены в блокноте «Результаты»."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дорожная карта:\n",
    "* Выборка 10% тренировочных наблюдений в случайном порядке\n",
    "* Конвертировать числовые столбцы в np.float32\n",
    "* Конвертировать логические столбцы в np.uint8\n",
    "* Горячее кодирование категориальных функций по мере необходимости\n",
    "* Удалить одну из каждой пары столбцов со всеми дублированными значениями (корреляция 1,0)\n",
    "* Удалить столбцы с более чем 90% пропущенных значений\n",
    "* Удалить столбцы с одним уникальным значением\n",
    "* Удалите одну из каждой пары столбцов с abs (корреляция)> 0,95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
